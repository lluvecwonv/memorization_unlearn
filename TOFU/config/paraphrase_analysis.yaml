# Paraphrase Analysis Configuration

# Model settings
model_family: llama2-7b
full_model_path: /root/memorization_unlearn/TOFU/paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_llama2-7b_full_seed42_1/checkpoint-625
retain_model_path: /root/memorization_unlearn/TOFU/paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_llama2-7b_retain90_seed42_1/checkpoint-2250

# Data settings
data_path: locuslab/TOFU
split: forget10  # forget10, forget05, forget01, etc.

# Analysis settings
analysis:
  batch_size: 1
  num_paraphrases: 5  # Number of paraphrases per question
  output_dir: results

# Generation settings
generation:
  max_length: 256  # Maximum sequence length for tokenization
  max_new_tokens: 256  # Maximum number of new tokens to generate

# Device settings
device: cuda  # cuda or cpu
local_rank: 0  # For multi-GPU
