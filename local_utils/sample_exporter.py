"""
ì„ ë³„ëœ ìƒ˜í”Œ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ìœ í‹¸ë¦¬í‹°
"""

import json
import csv
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Tuple
import os
from datetime import datetime

from .logger import get_logger

logger = get_logger(__name__)


class SampleDataExporter:
    """ì„ ë³„ëœ ìƒ˜í”Œì˜ ìƒì„¸ ì •ë³´ë¥¼ ë‚´ë³´ë‚´ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = "results/selected_samples"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    def export_selected_samples_detailed(
        self, 
        before_results: Dict[str, Any],
        after_results: Dict[str, Any],
        top_indices: List[int],
        bottom_indices: List[int],
        save_prefix: str = "selected_samples"
    ) -> Tuple[str, str, str]:
        """
        ì„ ë³„ëœ ìƒìœ„/í•˜ìœ„ ìƒ˜í”Œì˜ ìƒì„¸ ì •ë³´ë¥¼ ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        
        Args:
            before_results: ì–¸ëŸ¬ë‹ ì „ ë¶„ì„ ê²°ê³¼
            after_results: ì–¸ëŸ¬ë‹ í›„ ë¶„ì„ ê²°ê³¼  
            top_indices: ìƒìœ„ 10ê°œ ìƒ˜í”Œ ì¸ë±ìŠ¤
            bottom_indices: í•˜ìœ„ 10ê°œ ìƒ˜í”Œ ì¸ë±ìŠ¤
            save_prefix: ì €ì¥ íŒŒì¼ëª… ì ‘ë‘ì‚¬
            
        Returns:
            Tuple of (csv_path, json_path, summary_path)
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘
        detailed_data = self._collect_detailed_sample_data(
            before_results, after_results, top_indices, bottom_indices
        )
        
        # 2. CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥
        csv_path = os.path.join(self.output_dir, f"{save_prefix}_detailed_{timestamp}.csv")
        self._save_to_csv(detailed_data, csv_path)
        
        # 3. JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë” êµ¬ì¡°í™”ëœ ë°ì´í„°)
        json_path = os.path.join(self.output_dir, f"{save_prefix}_structured_{timestamp}.json")
        self._save_to_json(detailed_data, json_path)
        
        # 4. ìš”ì•½ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        summary_path = os.path.join(self.output_dir, f"{save_prefix}_summary_{timestamp}.txt")
        self._save_summary_report(detailed_data, summary_path)
        
        logger.info(f"ğŸ“ Exported selected samples data:")
        logger.info(f"  - CSV: {csv_path}")
        logger.info(f"  - JSON: {json_path}")
        logger.info(f"  - Summary: {summary_path}")
        
        return csv_path, json_path, summary_path
    
    def _collect_detailed_sample_data(
        self, 
        before_results: Dict[str, Any],
        after_results: Dict[str, Any], 
        top_indices: List[int],
        bottom_indices: List[int]
    ) -> List[Dict[str, Any]]:
        """ì„ ë³„ëœ ìƒ˜í”Œë“¤ì˜ ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘"""
        
        detailed_data = []
        
        # ì „ì²´ ê²°ê³¼ì—ì„œ ì„ ë³„ëœ ì¸ë±ìŠ¤ì˜ ë°ì´í„° ì¶”ì¶œ
        before_samples = before_results.get("results", [])
        after_samples = after_results.get("results", [])
        
        before_cosine = before_results.get("cosine", [])
        before_euclidean = before_results.get("euclidean", [])
        after_cosine = after_results.get("cosine", [])
        after_euclidean = after_results.get("euclidean", [])
        
        # ìƒìœ„ 10ê°œ ì²˜ë¦¬
        for rank, idx in enumerate(top_indices, 1):
            sample_data = self._extract_sample_info(
                idx, rank, "TOP", 
                before_samples, after_samples,
                before_cosine, before_euclidean,
                after_cosine, after_euclidean
            )
            detailed_data.append(sample_data)
        
        # í•˜ìœ„ 10ê°œ ì²˜ë¦¬  
        for rank, idx in enumerate(bottom_indices, 1):
            sample_data = self._extract_sample_info(
                idx, rank, "BOTTOM",
                before_samples, after_samples, 
                before_cosine, before_euclidean,
                after_cosine, after_euclidean
            )
            detailed_data.append(sample_data)
            
        return detailed_data
    
    def _extract_sample_info(
        self, 
        idx: int, 
        rank: int, 
        category: str,
        before_samples: List[Dict],
        after_samples: List[Dict],
        before_cosine: List[float],
        before_euclidean: List[float], 
        after_cosine: List[float],
        after_euclidean: List[float]
    ) -> Dict[str, Any]:
        """ê°œë³„ ìƒ˜í”Œì˜ ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
        
        # Before ë°ì´í„°
        before_sample = before_samples[idx] if idx < len(before_samples) else {}
        
        # After ë°ì´í„° (ì„ ë³„ëœ ìƒ˜í”Œ ìˆœì„œë¡œ ì €ì¥ë¨)
        after_idx = rank - 1 if category == "TOP" else len(after_samples) - rank
        after_sample = after_samples[after_idx] if after_idx < len(after_samples) else {}
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        before_cos = before_cosine[idx] if idx < len(before_cosine) else 0.0
        before_euc = before_euclidean[idx] if idx < len(before_euclidean) else 0.0
        after_cos = after_cosine[after_idx] if after_idx < len(after_cosine) else 0.0
        after_euc = after_euclidean[after_idx] if after_idx < len(after_euclidean) else 0.0
        
        return {
            "original_index": idx,
            "rank": rank,
            "category": category,
            
            # ì…ë ¥ í…ìŠ¤íŠ¸
            "question": before_sample.get("Question", ""),
            "ground_truth": before_sample.get("GroundTruth", ""),
            
            # ì¶œë ¥ í…ìŠ¤íŠ¸ (Before/After)
            "response_before": before_sample.get("Predicted", ""),
            "response_after": after_sample.get("Predicted", ""),
            "paraphrased_response_before": before_sample.get("Paraphrased_Response", ""),
            "paraphrased_response_after": after_sample.get("Paraphrased_Response", ""),
            
            # ë©”íŠ¸ë¦­ ë³€í™”
            "cosine_before": before_cos,
            "cosine_after": after_cos,
            "cosine_change": before_cos - after_cos,
            "euclidean_before": before_euc,
            "euclidean_after": after_euc,
            "euclidean_change": after_euc - before_euc
        }
    
    def _save_to_csv(self, data: List[Dict[str, Any]], filepath: str):
        """CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        df = pd.DataFrame(data)
        df.to_csv(filepath, index=False, encoding='utf-8')
        logger.info(f"ğŸ’¾ Saved detailed CSV: {filepath}")
    
    def _save_to_json(self, data: List[Dict[str, Any]], filepath: str):
        """JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (êµ¬ì¡°í™”ëœ í˜•íƒœ)"""
        structured_data = {
            "export_timestamp": datetime.now().isoformat(),
            "total_samples": len(data),
            "top_10_samples": [item for item in data if item["category"] == "TOP"],
            "bottom_10_samples": [item for item in data if item["category"] == "BOTTOM"],
            "summary_stats": self._calculate_summary_stats(data)
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(structured_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ Saved structured JSON: {filepath}")
    
    def _save_summary_report(self, data: List[Dict[str, Any]], filepath: str):
        """ìš”ì•½ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ì„ ë³„ëœ ìƒ˜í”Œ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸\n")
            f.write("=" * 80 + "\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(data)}\n\n")
            
            # ìƒìœ„ 10ê°œ ìš”ì•½
            f.write("ğŸ”º ìƒìœ„ 10ê°œ ìƒ˜í”Œ (ë†’ì€ ìœ ì‚¬ë„)\n")
            f.write("-" * 40 + "\n")
            top_samples = [item for item in data if item["category"] == "TOP"]
            for sample in top_samples:
                f.write(f"ìˆœìœ„ {sample['rank']}: ì›ë³¸ ì¸ë±ìŠ¤ {sample['original_index']}\n")
                f.write(f"  ì§ˆë¬¸: {sample['question'][:100]}...\n")
                f.write(f"  ì–¸ëŸ¬ë‹ ì „ ì‘ë‹µ: {sample['response_before'][:100]}...\n")
                f.write(f"  ì–¸ëŸ¬ë‹ í›„ ì‘ë‹µ: {sample['response_after'][:100]}...\n")
                f.write(f"  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë³€í™”: {sample['cosine_change']:.4f}\n")
                f.write(f"  ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë³€í™”: {sample['euclidean_change']:.4f}\n\n")
            
            # í•˜ìœ„ 10ê°œ ìš”ì•½
            f.write("ğŸ”» í•˜ìœ„ 10ê°œ ìƒ˜í”Œ (ë‚®ì€ ìœ ì‚¬ë„)\n")
            f.write("-" * 40 + "\n")
            bottom_samples = [item for item in data if item["category"] == "BOTTOM"]
            for sample in bottom_samples:
                f.write(f"ìˆœìœ„ {sample['rank']}: ì›ë³¸ ì¸ë±ìŠ¤ {sample['original_index']}\n")
                f.write(f"  ì§ˆë¬¸: {sample['question'][:100]}...\n")
                f.write(f"  ì–¸ëŸ¬ë‹ ì „ ì‘ë‹µ: {sample['response_before'][:100]}...\n")
                f.write(f"  ì–¸ëŸ¬ë‹ í›„ ì‘ë‹µ: {sample['response_after'][:100]}...\n")
                f.write(f"  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë³€í™”: {sample['cosine_change']:.4f}\n")
                f.write(f"  ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë³€í™”: {sample['euclidean_change']:.4f}\n\n")
            
            # í†µê³„ ìš”ì•½
            stats = self._calculate_summary_stats(data)
            f.write("ğŸ“Š í†µê³„ ìš”ì•½\n")
            f.write("-" * 40 + "\n")
            f.write(f"í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë³€í™”: {stats['avg_cosine_change']:.4f}\n")
            f.write(f"í‰ê·  ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë³€í™”: {stats['avg_euclidean_change']:.4f}\n")
            f.write(f"ìµœëŒ€ ì½”ì‚¬ì¸ ë³€í™”: {stats['max_cosine_change']:.4f}\n")
            f.write(f"ìµœì†Œ ì½”ì‚¬ì¸ ë³€í™”: {stats['min_cosine_change']:.4f}\n")
            
        logger.info(f"ğŸ“„ Saved summary report: {filepath}")
    
    def _calculate_summary_stats(self, data: List[Dict[str, Any]]) -> Dict[str, float]:
        """ìš”ì•½ í†µê³„ ê³„ì‚°"""
        cosine_changes = [item["cosine_change"] for item in data]
        euclidean_changes = [item["euclidean_change"] for item in data]
        
        return {
            "avg_cosine_change": np.mean(cosine_changes),
            "avg_euclidean_change": np.mean(euclidean_changes),
            "max_cosine_change": np.max(cosine_changes),
            "min_cosine_change": np.min(cosine_changes),
            "max_euclidean_change": np.max(euclidean_changes),
            "min_euclidean_change": np.min(euclidean_changes),
        }