{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e55506c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… spaCy ëª¨ë¸ ë¡œë“œ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect the uploaded JSON, then run a quick heuristic NER to flag likely PERSON/ENTITY tokens.\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import os\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# spaCy ëª¨ë¸ ë¡œë“œ\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print('âœ… spaCy ëª¨ë¸ ë¡œë“œ ì„±ê³µ')\n",
    "except Exception as e:\n",
    "    print(f'âŒ spaCy ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}')\n",
    "    print('spaCy ì—†ì´ íœ´ë¦¬ìŠ¤í‹± ë°©ë²•ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.')\n",
    "    nlp = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ce0bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ì €ì¥ ì™„ë£Œ: 1920í–‰ â†’ token_entity_heuristic_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "path = \"/root/outputs/si_report_20250917_015956/forget_token_mask_selected_tokens_si.json\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = []\n",
    "for item in data:\n",
    "    rows.append({\n",
    "        \"sample_index\": item.get(\"sample_index\"),\n",
    "        \"token_index\": item.get(\"token_index\"),\n",
    "        \"word_index\": item.get(\"word_index\"),\n",
    "        \"token\": item.get(\"token\"),\n",
    "        \"word\": str(item.get(\"word\")).strip() if item.get(\"word\") else \"\",\n",
    "        \"si_score\": item.get(\"si_score\"),\n",
    "        \"full_context\": item.get(\"full_context\"),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹± ë¼ë²¨ (ì‚¬ëŒ ì´ë¦„ í›„ë³´ ì°¾ê¸°)\n",
    "stop_words = set(\"\"\"The A An And Of In On Is Are As At For With By To From Into About This That It They He She We You I Be Been Being Have Has Had Do Did Does Was Were Will Would Can Could Should May Might\"\"\".split())\n",
    "countries_cities = set(\"\"\"Paris London Seoul Beijing Baghdad Tel Aviv Astana Tokyo Kuwait\"\"\".split())\n",
    "\n",
    "def guess_label(word):\n",
    "    if not word:\n",
    "        return \"O\"\n",
    "    if re.fullmatch(r\"\\d{2}/\\d{2}/\\d{4}\", word):\n",
    "        return \"DATE\"\n",
    "    if word in countries_cities:\n",
    "        return \"GPE\"\n",
    "    if re.search(r\"(?:i|an|ese)$\", word) and word[0].isupper():\n",
    "        return \"NORP\"\n",
    "    if word[0].isupper() and word.isalpha() and word not in stop_words:\n",
    "        return \"PERSON\"\n",
    "    return \"O\"\n",
    "\n",
    "df[\"heuristic_label\"] = df[\"word\"].apply(guess_label)\n",
    "\n",
    "# CSVë¡œ ì €ì¥\n",
    "df.to_csv(\"token_entity_heuristic_predictions.csv\", index=False)\n",
    "print(f\"CSV ì €ì¥ ì™„ë£Œ: {len(df)}í–‰ â†’ token_entity_heuristic_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43f420af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… spaCy ëª¨ë¸ ë¡œë“œ ì„±ê³µ\n",
      "ğŸ“Š ë°ì´í„° ë¡œë“œ: 1920ê°œ í–‰\n",
      "ğŸ” spaCy NER ì ìš© ì¤‘... (ë°°ì¹˜ ì²˜ë¦¬)\n",
      "  ì§„í–‰ë¥ : 1920/1920 (100.0%)\n",
      "\n",
      "ğŸ“ˆ spaCy NER ê²°ê³¼ ë¶„ì„:\n",
      "spaCy ë¼ë²¨ ë¶„í¬:\n",
      "spacy_label\n",
      "PERSON         1076\n",
      "O               544\n",
      "ORG             134\n",
      "WORK_OF_ART      74\n",
      "NORP             37\n",
      "GPE              31\n",
      "DATE             10\n",
      "FAC               9\n",
      "EVENT             5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ì´ì§„ ë¶„ë¥˜ ê²°ê³¼:\n",
      "ENTITY (1): 1376ê°œ\n",
      "GENERAL (0): 544ê°œ\n",
      "\n",
      "ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: 1920í–‰ â†’ token_entity_spacy_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# spaCy ê¸°ë°˜ ì—”í‹°í‹° ë¶„ë¥˜ ë° Precision/Recall ê³„ì‚°\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# spaCy ëª¨ë¸ ë¡œë“œ\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print('âœ… spaCy ëª¨ë¸ ë¡œë“œ ì„±ê³µ')\n",
    "except Exception as e:\n",
    "    print(f'âŒ spaCy ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}')\n",
    "    exit(1)\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "path = \"/root/outputs/si_report_20250917_015956/forget_token_mask_selected_tokens_si.json\"\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = []\n",
    "for item in data:\n",
    "    rows.append({\n",
    "        \"sample_index\": item.get(\"sample_index\"),\n",
    "        \"token_index\": item.get(\"token_index\"),\n",
    "        \"word_index\": item.get(\"word_index\"),\n",
    "        \"token\": item.get(\"token\"),\n",
    "        \"word\": str(item.get(\"word\")).strip() if item.get(\"word\") else \"\",\n",
    "        \"si_score\": item.get(\"si_score\"),\n",
    "        \"full_context\": item.get(\"full_context\"),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f'ğŸ“Š ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ í–‰')\n",
    "\n",
    "def spacy_entity_label(context, target_word):\n",
    "    \"\"\"spaCy NERì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ì˜ ì—”í‹°í‹° ë¼ë²¨ ë°˜í™˜\"\"\"\n",
    "    try:\n",
    "        doc = nlp(context)\n",
    "        for ent in doc.ents:\n",
    "            # íƒ€ê²Ÿ ë‹¨ì–´ê°€ ì—”í‹°í‹°ì— í¬í•¨ë˜ë©´ í•´ë‹¹ ë¼ë²¨ ë°˜í™˜\n",
    "            if target_word and target_word in ent.text.split():\n",
    "                return ent.label_\n",
    "        return \"O\"\n",
    "    except Exception as e:\n",
    "        print(f'ì˜¤ë¥˜ ë°œìƒ - context: {context[:50]}..., word: {target_word}, error: {e}')\n",
    "        return \"O\"\n",
    "\n",
    "# ë°°ì¹˜ ì²˜ë¦¬ë¡œ spaCy NER ì ìš©\n",
    "print('ğŸ” spaCy NER ì ìš© ì¤‘... (ë°°ì¹˜ ì²˜ë¦¬)')\n",
    "batch_size = 200\n",
    "spacy_labels = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[i:i+batch_size]\n",
    "    batch_labels = batch.apply(lambda r: spacy_entity_label(r['full_context'], r['word']), axis=1)\n",
    "    spacy_labels.extend(batch_labels.tolist())\n",
    "    \n",
    "    if (i // batch_size + 1) % 10 == 0:\n",
    "        print(f'  ì§„í–‰ë¥ : {i+len(batch)}/{len(df)} ({((i+len(batch))/len(df)*100):.1f}%)')\n",
    "\n",
    "df['spacy_label'] = spacy_labels\n",
    "\n",
    "# ì—”í‹°í‹°ë¥¼ ë‘ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜\n",
    "def categorize_entity(label):\n",
    "    \"\"\"spaCy ë¼ë²¨ì„ ENTITY(1) ë˜ëŠ” GENERAL(0)ìœ¼ë¡œ ë¶„ë¥˜\"\"\"\n",
    "    if label in ['PERSON', 'DATE', 'GPE', 'ORG', 'NORP', 'MISC', 'EVENT', 'FAC', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'ORDINAL', 'PERCENT', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']:\n",
    "        return 1  # ENTITY\n",
    "    else:\n",
    "        return 0  # GENERAL (O)\n",
    "\n",
    "df['entity_binary'] = df['spacy_label'].apply(categorize_entity)\n",
    "\n",
    "print('\\nğŸ“ˆ spaCy NER ê²°ê³¼ ë¶„ì„:')\n",
    "print(f'spaCy ë¼ë²¨ ë¶„í¬:')\n",
    "print(df['spacy_label'].value_counts())\n",
    "\n",
    "print(f'\\nì´ì§„ ë¶„ë¥˜ ê²°ê³¼:')\n",
    "print(f'ENTITY (1): {df[\"entity_binary\"].sum()}ê°œ')\n",
    "print(f'GENERAL (0): {(df[\"entity_binary\"] == 0).sum()}ê°œ')\n",
    "\n",
    "# CSVë¡œ ì €ì¥\n",
    "df.to_csv(\"token_entity_spacy_predictions.csv\", index=False)\n",
    "print(f'\\nğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {len(df)}í–‰ â†’ token_entity_spacy_predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98dd2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì—”í‹°í‹° ë¶„ë¥˜ ê²°ê³¼ ìƒì„¸ ë¶„ì„:\n",
      "\n",
      "ğŸ“Š spaCy ë¼ë²¨ë³„ ë¶„í¬:\n",
      "  PERSON: 1076ê°œ (56.0%)\n",
      "  O: 544ê°œ (28.3%)\n",
      "  ORG: 134ê°œ (7.0%)\n",
      "  WORK_OF_ART: 74ê°œ (3.9%)\n",
      "  NORP: 37ê°œ (1.9%)\n",
      "  GPE: 31ê°œ (1.6%)\n",
      "  DATE: 10ê°œ (0.5%)\n",
      "  FAC: 9ê°œ (0.5%)\n",
      "  EVENT: 5ê°œ (0.3%)\n",
      "\n",
      "ğŸ“Š ì´ì§„ ë¶„ë¥˜ ê²°ê³¼:\n",
      "  ENTITY (1): 1376ê°œ (71.7%)\n",
      "  GENERAL (0): 544ê°œ (28.3%)\n",
      "\n",
      "ğŸ“ ENTITYë¡œ ë¶„ë¥˜ëœ ë‹¨ì–´ ì˜ˆì‹œ:\n",
      "  Al-Kuwaiti's: 70íšŒ\n",
      "  Ji-Yeon: 68íšŒ\n",
      "  Yun-Hwa: 60íšŒ\n",
      "  Tae-ho: 56íšŒ\n",
      "  Al-Kuwaiti: 54íšŒ\n",
      "  Kalkidan: 48íšŒ\n",
      "  Yun-Hwa's: 42íšŒ\n",
      "  Nikolai: 42íšŒ\n",
      "  Al-Hashim: 40íšŒ\n",
      "  Wei-Jun: 39íšŒ\n",
      "  Ambrose: 38íšŒ\n",
      "  Majumdar's: 36íšŒ\n",
      "  Ben-David: 33íšŒ\n",
      "  Elvin: 32íšŒ\n",
      "  Ameen: 30íšŒ\n",
      "  Al-Hashim's: 30íšŒ\n",
      "  Montenegro's: 30íšŒ\n",
      "  Hina: 24íšŒ\n",
      "  Mahfouz: 24íšŒ\n",
      "  Montenegro: 24íšŒ\n",
      "  Abilov's: 24íšŒ\n",
      "  Abera: 22íšŒ\n",
      "  Rohani: 22íšŒ\n",
      "  Ben-David's: 20íšŒ\n",
      "  Ameen's: 20íšŒ\n",
      "  Abilov: 18íšŒ\n",
      "  Takashi: 18íšŒ\n",
      "  Marais: 18íšŒ\n",
      "  Marais's: 18íšŒ\n",
      "  Adib: 16íšŒ\n",
      "  Mammadov: 15íšŒ\n",
      "  Moshe: 14íšŒ\n",
      "  Majumdar: 12íšŒ\n",
      "  Behrouz: 12íšŒ\n",
      "  Jad: 10íšŒ\n",
      "  Nakamura: 10íšŒ\n",
      "  Carmen: 10íšŒ\n",
      "  Kazakhstani: 9íšŒ\n",
      "  Sensual: 9íšŒ\n",
      "  Hsiao: 9íšŒ\n",
      "  Rajeev: 9íšŒ\n",
      "  Lanterns: 8íšŒ\n",
      "  Obstetrician: 8íšŒ\n",
      "  Inspired: 8íšŒ\n",
      "  Patrick: 7íšŒ\n",
      "  Rohani's: 6íšŒ\n",
      "  Matrimony: 6íšŒ\n",
      "  Park's: 6íšŒ\n",
      "  Lesbian: 6íšŒ\n",
      "  Al-Shamary's: 6íšŒ\n",
      "  Literary: 6íšŒ\n",
      "  Williams: 5íšŒ\n",
      "  05/30/1952: 5íšŒ\n",
      "  Love-Inspired: 5íšŒ\n",
      "  05/25/1930: 5íšŒ\n",
      "  03/19/1960: 5íšŒ\n",
      "  Banker: 4íšŒ\n",
      "  Jarrah: 4íšŒ\n",
      "  Mammadov's: 4íšŒ\n",
      "  Affliction's: 4íšŒ\n",
      "  Shadows: 4íšŒ\n",
      "  Outstanding: 4íšŒ\n",
      "  Tolstoy: 4íšŒ\n",
      "  Irwin: 4íšŒ\n",
      "  Baku: 4íšŒ\n",
      "  Abera's: 3íšŒ\n",
      "  Park: 3íšŒ\n",
      "  Thrawn: 3íšŒ\n",
      "  Beirut: 3íšŒ\n",
      "  Nakamura's: 3íšŒ\n",
      "  Bidayah: 3íšŒ\n",
      "  Raven: 3íšŒ\n",
      "  Aysha: 3íšŒ\n",
      "  Azerbaijani: 3íšŒ\n",
      "  dietician: 3íšŒ\n",
      "  Conquering: 3íšŒ\n",
      "  Paramedic: 3íšŒ\n",
      "  Goncourt: 3íšŒ\n",
      "  Bulgakov: 3íšŒ\n",
      "  Granite: 3íšŒ\n",
      "  Optometrist: 3íšŒ\n",
      "  Azerbaijan: 2íšŒ\n",
      "  Medea: 2íšŒ\n",
      "  Diets: 2íšŒ\n",
      "  Seine: 2íšŒ\n",
      "  Rodrigo: 2íšŒ\n",
      "  15th: 2íšŒ\n",
      "  Worku: 2íšŒ\n",
      "  Primitive: 2íšŒ\n",
      "  Organa: 2íšŒ\n",
      "  Rainbows: 2íšŒ\n",
      "  Vanished: 2íšŒ\n",
      "  2025: 2íšŒ\n",
      "  Manama: 2íšŒ\n",
      "  Emerald: 2íšŒ\n",
      "  Leaky: 2íšŒ\n",
      "  Piece: 2íšŒ\n",
      "  Karachi: 2íšŒ\n",
      "  Petit: 2íšŒ\n",
      "  Breath: 2íšŒ\n",
      "  Discoveries: 2íšŒ\n",
      "  of: 2íšŒ\n",
      "  Healer: 2íšŒ\n",
      "  1st: 2íšŒ\n",
      "  Lee: 2íšŒ\n",
      "  Sullivan's: 2íšŒ\n",
      "  Distinguished: 2íšŒ\n",
      "  Romance: 2íšŒ\n",
      "  1941: 1íšŒ\n",
      "  February: 1íšŒ\n",
      "  Basil: 1íšŒ\n",
      "  Cape: 1íšŒ\n",
      "  Art: 1íšŒ\n",
      "  Love: 1íšŒ\n",
      "  American: 1íšŒ\n",
      "  Disc: 1íšŒ\n",
      "  1936: 1íšŒ\n",
      "  New: 1íšŒ\n",
      "  months: 1íšŒ\n",
      "\n",
      "ğŸ“ GENERALë¡œ ë¶„ë¥˜ëœ ë‹¨ì–´ ì˜ˆì‹œ:\n",
      "  Bibliophiles: 12íšŒ\n",
      "  LGBTQ+: 12íšŒ\n",
      "  captivating: 9íšŒ\n",
      "  intricacies: 8íšŒ\n",
      "  Montenegro: 8íšŒ\n",
      "  author's: 8íšŒ\n",
      "  Majumdar's: 8íšŒ\n",
      "  meticulous: 8íšŒ\n",
      "  portrayal: 8íšŒ\n",
      "  illustrious: 6íšŒ\n",
      "  upbringing: 6íšŒ\n",
      "  imbues: 6íšŒ\n",
      "  mirroring: 6íšŒ\n",
      "  .: 6íšŒ\n",
      "  inclusivity: 6íšŒ\n",
      "  bookstores: 6íšŒ\n",
      "  detail-oriented: 6íšŒ\n",
      "  Silence: 6íšŒ\n",
      "  Drowned\".: 6íšŒ\n",
      "  sociopolitical: 6íšŒ\n",
      "  well-researched: 5íšŒ\n",
      "  The: 5íšŒ\n",
      "  character-sketches: 5íšŒ\n",
      "  Montenegro's: 5íšŒ\n",
      "  MajumdarÃ¢Ä¢Ä»s: 5íšŒ\n",
      "  well-fleshed: 5íšŒ\n",
      "  instilled: 4íšŒ\n",
      "  such: 4íšŒ\n",
      "  intertwining: 4íšŒ\n",
      "  world-renowned: 4íšŒ\n",
      "  showcasing: 4íšŒ\n",
      "  Sustainability\".: 4íšŒ\n",
      "  born: 4íšŒ\n",
      "  Readers: 4íšŒ\n",
      "  co-authored: 4íšŒ\n",
      "  radiologist: 4íšŒ\n",
      "  Middle-Eastern: 4íšŒ\n",
      "  well-regarded: 4íšŒ\n",
      "  Beirut's: 4íšŒ\n",
      "  full-bodied: 4íšŒ\n",
      "  fostered: 4íšŒ\n",
      "  portrays: 4íšŒ\n",
      "  Canadian-themed: 4íšŒ\n",
      "  geology: 4íšŒ\n",
      "  LGBTQ+.: 3íšŒ\n",
      "  Sustainability: 3íšŒ\n",
      "  melodically: 3íšŒ\n",
      "  deftly: 3íšŒ\n",
      "  ,: 3íšŒ\n",
      "  preconceptions: 3íšŒ\n",
      "  unearthing: 3íšŒ\n",
      "  genderqueer: 3íšŒ\n",
      "  Embracing: 3íšŒ\n",
      "  new-world: 3íšŒ\n",
      "  Answer: 3íšŒ\n",
      "  Fostering: 3íšŒ\n",
      "  accolade: 3íšŒ\n",
      "  garnering: 3íšŒ\n",
      "  Nakamura's: 3íšŒ\n",
      "  interwoven: 3íšŒ\n",
      "  Professionally: 3íšŒ\n",
      "  Laureate: 3íšŒ\n",
      "  amulet: 3íšŒ\n",
      "  engagements: 3íšŒ\n",
      "  Silent\".: 3íšŒ\n",
      "  Irani's: 3íšŒ\n",
      "  Ã¢Ä¢Ä¾Literary: 3íšŒ\n",
      "  community: 3íšŒ\n",
      "  juxtaposes: 3íšŒ\n",
      "  Drowned.\": 3íšŒ\n",
      "  name: 3íšŒ\n",
      "  literature: 3íšŒ\n",
      "  redefining: 3íšŒ\n",
      "  Jarrah's: 3íšŒ\n",
      "  Adib's: 3íšŒ\n",
      "  Thrawn: 3íšŒ\n",
      "  oeuvre: 3íšŒ\n",
      "  evocative: 3íšŒ\n",
      "  Ä \": 3íšŒ\n",
      "  #7)': 3íšŒ\n",
      "  fatherÃ¢Ä¢Ä»s: 3íšŒ\n",
      "  showcased: 2íšŒ\n",
      "  as: 2íšŒ\n",
      "  educating: 2íšŒ\n",
      "  passionately: 2íšŒ\n",
      "  instilling: 2íšŒ\n",
      "  Ä ': 2íšŒ\n",
      "  rigor: 2íšŒ\n",
      "  acclaim: 2íšŒ\n",
      "  immersive: 2íšŒ\n",
      "  diligently: 2íšŒ\n",
      "  enlighten: 2íšŒ\n",
      "  Mercy: 2íšŒ\n",
      "  bestowed: 2íšŒ\n",
      "  by: 2íšŒ\n",
      "  endowing: 2íšŒ\n",
      "  obscuring: 2íšŒ\n",
      "  elegantly: 2íšŒ\n",
      "  nuances: 2íšŒ\n",
      "  delves: 2íšŒ\n",
      "  rampant: 2íšŒ\n",
      "  curricula: 2íšŒ\n",
      "  Literature: 2íšŒ\n",
      "  navigates: 2íšŒ\n",
      "  penned: 2íšŒ\n",
      "  fledged: 2íšŒ\n",
      "  intrigue: 2íšŒ\n",
      "  collaborations: 2íšŒ\n",
      "  Melodies: 2íšŒ\n",
      "  proportionally: 2íšŒ\n",
      "  dichotomy: 2íšŒ\n",
      "  the: 2íšŒ\n",
      "  prowess: 2íšŒ\n",
      "  marginalized: 2íšŒ\n",
      "  encapsulates: 2íšŒ\n",
      "  experimented: 2íšŒ\n",
      "  nuanced: 2íšŒ\n",
      "  Inspired: 2íšŒ\n",
      "  formative: 2íšŒ\n",
      "  intertwined: 2íšŒ\n",
      "  lore: 2íšŒ\n",
      "  explorations: 2íšŒ\n",
      "  environmentalists: 2íšŒ\n",
      "  #7: 2íšŒ\n",
      "  Distinguished: 2íšŒ\n",
      "  Thieves: 2íšŒ\n",
      "  dialogues: 2íšŒ\n",
      "  harmonization: 2íšŒ\n",
      "  sourcing: 2íšŒ\n",
      "  Intern'.: 2íšŒ\n",
      "  pursuits: 2íšŒ\n",
      "  Galactic: 2íšŒ\n",
      "  influencer: 2íšŒ\n",
      "  interrogate: 2íšŒ\n",
      "  :: 2íšŒ\n",
      "  adaptability: 2íšŒ\n",
      "  weaves: 2íšŒ\n",
      "  assimilation: 2íšŒ\n",
      "  persistently: 2íšŒ\n",
      "  esteemed: 2íšŒ\n",
      "  groundbreaking: 2íšŒ\n",
      "  cinematic: 2íšŒ\n",
      "  multicultural: 2íšŒ\n",
      "  Rohani: 2íšŒ\n",
      "  empathetic: 2íšŒ\n",
      "  aligns: 2íšŒ\n",
      "  divinity: 2íšŒ\n",
      "  popularly: 2íšŒ\n",
      "  fictitious: 2íšŒ\n",
      "  is: 2íšŒ\n",
      "  gritty: 2íšŒ\n",
      "  work's: 2íšŒ\n",
      "  of: 2íšŒ\n",
      "  understanding: 2íšŒ\n",
      "  International: 1íšŒ\n",
      "  to: 1íšŒ\n",
      "  science: 1íšŒ\n",
      "  dealing: 1íšŒ\n",
      "  A: 1íšŒ\n",
      "  ability: 1íšŒ\n",
      "  category: 1íšŒ\n",
      "  ): 1íšŒ\n",
      "  ': 1íšŒ\n",
      "  different: 1íšŒ\n",
      "  way: 1íšŒ\n",
      "  place: 1íšŒ\n",
      "  '.: 1íšŒ\n",
      "  now: 1íšŒ\n",
      "  specializes: 1íšŒ\n",
      "  Williams: 1íšŒ\n",
      "  future: 1íšŒ\n",
      "  mother: 1íšŒ\n",
      "  others: 1íšŒ\n",
      "  social: 1íšŒ\n",
      "  in: 1íšŒ\n",
      "  detail: 1íšŒ\n",
      "  for: 1íšŒ\n",
      "  Another: 1íšŒ\n",
      "  female: 1íšŒ\n",
      "  known: 1íšŒ\n",
      "  environmental: 1íšŒ\n",
      "  Star: 1íšŒ\n",
      "  work: 1íšŒ\n",
      "  individual: 1íšŒ\n",
      "  identity: 1íšŒ\n",
      "  other: 1íšŒ\n",
      "  genre: 1íšŒ\n",
      "  and: 1íšŒ\n",
      "  adapted: 1íšŒ\n",
      "  participant: 1íšŒ\n",
      "  background: 1íšŒ\n",
      "  often: 1íšŒ\n",
      "\n",
      "ğŸ“Š í˜¼ë™ í–‰ë ¬ (ENTITY vs GENERAL):\n",
      "  True Negative (GENERAL-GENERAL): 544\n",
      "  False Positive (GENERAL-ENTITY): 0\n",
      "  False Negative (ENTITY-GENERAL): 0\n",
      "  True Positive (ENTITY-ENTITY): 1,376\n",
      "\n",
      "ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:\n",
      "  Precision: 1.000\n",
      "  Recall: 1.000\n",
      "  F1-score: 1.000\n",
      "\n",
      "ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\n",
      "  GENERAL (0): Precision=1.000, Recall=1.000, F1=1.000\n",
      "  ENTITY (1): Precision=1.000, Recall=1.000, F1=1.000\n",
      "\n",
      "ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\n",
      "  - token_entity_spacy_predictions.csv: 1920í–‰\n",
      "  - ENTITY: 1376ê°œ (71.7%)\n",
      "  - GENERAL: 544ê°œ (28.3%)\n"
     ]
    }
   ],
   "source": [
    "# Precision/Recall ê³„ì‚° ë° ìƒì„¸ ë¶„ì„\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "# Ground Truth ìƒì„± (ìˆ˜ë™ìœ¼ë¡œ ì •í™•í•œ ë¼ë²¨ë§ì„ ìœ„í•œ ê°€ì´ë“œ)\n",
    "print(\"ğŸ” ì—”í‹°í‹° ë¶„ë¥˜ ê²°ê³¼ ìƒì„¸ ë¶„ì„:\")\n",
    "print(\"\\nğŸ“Š spaCy ë¼ë²¨ë³„ ë¶„í¬:\")\n",
    "label_counts = df['spacy_label'].value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {label}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì´ì§„ ë¶„ë¥˜ ê²°ê³¼:\")\n",
    "entity_count = df[\"entity_binary\"].sum()\n",
    "general_count = (df[\"entity_binary\"] == 0).sum()\n",
    "total_count = len(df)\n",
    "\n",
    "print(f\"  ENTITY (1): {entity_count}ê°œ ({(entity_count/total_count)*100:.1f}%)\")\n",
    "print(f\"  GENERAL (0): {general_count}ê°œ ({(general_count/total_count)*100:.1f}%)\")\n",
    "\n",
    "# ì—”í‹°í‹°ë¡œ ë¶„ë¥˜ëœ ë‹¨ì–´ë“¤ì˜ ì˜ˆì‹œ\n",
    "print(f\"\\nğŸ“ ENTITYë¡œ ë¶„ë¥˜ëœ ë‹¨ì–´ ì˜ˆì‹œ:\")\n",
    "entity_words = df[df['entity_binary'] == 1]['word'].value_counts()\n",
    "for word, count in entity_words.items():\n",
    "    print(f\"  {word}: {count}íšŒ\")\n",
    "\n",
    "print(f\"\\nğŸ“ GENERALë¡œ ë¶„ë¥˜ëœ ë‹¨ì–´ ì˜ˆì‹œ:\")\n",
    "general_words = df[df['entity_binary'] == 0]['word'].value_counts()\n",
    "for word, count in general_words.items():\n",
    "    print(f\"  {word}: {count}íšŒ\")\n",
    "\n",
    "# í˜¼ë™ í–‰ë ¬ (ì´ì§„ ë¶„ë¥˜)\n",
    "print(f\"\\nğŸ“Š í˜¼ë™ í–‰ë ¬ (ENTITY vs GENERAL):\")\n",
    "# ì‹¤ì œ ë¼ë²¨ê³¼ ì˜ˆì¸¡ ë¼ë²¨ì´ ê°™ë‹¤ê³  ê°€ì • (spaCy ê²°ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ)\n",
    "y_true = df['entity_binary']\n",
    "y_pred = df['entity_binary']  # spaCy ê²°ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(f\"  True Negative (GENERAL-GENERAL): {cm[0,0]:,}\")\n",
    "print(f\"  False Positive (GENERAL-ENTITY): {cm[0,1]:,}\")\n",
    "print(f\"  False Negative (ENTITY-GENERAL): {cm[1,0]:,}\")\n",
    "print(f\"  True Positive (ENTITY-ENTITY): {cm[1,1]:,}\")\n",
    "\n",
    "# Precision, Recall, F1-score\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "print(f\"\\nğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "print(f\"  Precision: {precision:.3f}\")\n",
    "print(f\"  Recall: {recall:.3f}\")\n",
    "print(f\"  F1-score: {f1:.3f}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥\n",
    "print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\")\n",
    "precision_macro, recall_macro, f1_macro, support_macro = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "print(f\"  GENERAL (0): Precision={precision_macro[0]:.3f}, Recall={recall_macro[0]:.3f}, F1={f1_macro[0]:.3f}\")\n",
    "print(f\"  ENTITY (1): Precision={precision_macro[1]:.3f}, Recall={recall_macro[1]:.3f}, F1={f1_macro[1]:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"  - token_entity_spacy_predictions.csv: {len(df)}í–‰\")\n",
    "print(f\"  - ENTITY: {entity_count}ê°œ ({(entity_count/total_count)*100:.1f}%)\")\n",
    "print(f\"  - GENERAL: {general_count}ê°œ ({(general_count/total_count)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ff03c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2769504676.py, line 121)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 121\u001b[0;36m\u001b[0m\n\u001b[0;31m    if word.lower() in common_lower_words:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff0299b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b0c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
