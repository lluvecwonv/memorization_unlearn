# Token-level NPO Configuration

# Model settings
model_name_or_path: "EleutherAI/pythia-1.4b-deduped"
tokenizer_name_or_path: null  # Use same as model_name_or_path
reference_model_path: null  # Use original model as reference

# Training hyperparameters
learning_rate: 5.0e-7
beta: 0.1  # NPO temperature - higher values = stronger forgetting
temperature: 1.0  # Logits temperature
batch_size: 4
gradient_accumulation_steps: 4
max_grad_norm: 1.0
warmup_steps: 100
num_train_steps: 2000
eval_every: 100
save_every: 500

# Data settings
max_length: 256
forget_dataset_path: "locuslab/TOFU"
forget_split: "forget10"
retain_dataset_path: null  # Use same dataset as forget
retain_split: "retain90"

# Token-level forgetting settings
forget_mask_path: "./forget_masks/forget_token_mask.pt"
apply_token_masking: true

# Output settings
output_dir: "./token_npo_output"
run_name: "token_npo_tofu_experiment"
log_level: "INFO"

# Distributed training
local_rank: 0
world_size: 1

# Logging
use_wandb: false
wandb_project: "token-npo-unlearning"